{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp testing\n",
    "\n",
    "%pip install -q langchain_core\n",
    "%pip install -q langchain_openai\n",
    "%pip install -q psycopg2-binary\n",
    "%pip install -q nbdev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstPrompt = PromptTemplate.from_template(\"\"\"Return one ore more json objects together in an array to describe the jobs in a job posting. If there is only one job posting presented here, return a json object containing a summary of every separate piece of information in the job posting. If the job describes multiple roles, create separate json objects for each role. Here is the job posting:\\n{job_posting}\"\"\")\n",
    "\n",
    "subsequentPrompt = PromptTemplate.from_template(\"\"\"You will be returning one ore more json objects together in an array to describe the jobs in a job posting. Here are examples of the format of the json object you should return:\\n{json_examples}\\nHere are the key values currently being used to categorize jobs:\\n{key_values}.\\n If there is only one job posting presented here, return a json object containing a summary of every separate piece of information in the job posting. If the job describes multiple roles, create a separate json object for each role. Use the existing key values where they are relevant. If there is no relevant existing key, add new, relevant key to your json object:\\n{job_posting}\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt  = subsequentPrompt.format(job_posting=\"This is a job posting\", json_examples=\"[{\\\"role\\\": \\\"Software Engineer\\\", \\\"location\\\": \\\"San Francisco\\\", \\\"salary\\\": \\\"$120,000\\\"}, {\\\"role\\\": \\\"Data Scientist\\\", \\\"location\\\": \\\"New York\\\", \\\"salary\\\": \\\"$150,000\\\"}]\", key_values=\"role, location, salary\")\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Opening JSON file\n",
    "f = open('../posts.json')\n",
    "\n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "posts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import psycopg2\n",
    "\n",
    "def connect():\n",
    "    conn = psycopg2.connect(\"dbname=Bumpant user=Bumpant password=ampegskb\")\n",
    "    cur = conn.cursor()\n",
    "    return conn, cur\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=Bumpant user=Bumpant password=ampegskb\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\n",
    "    \"\"\"CREATE TABLE IF NOT EXISTS parsedPosts (\n",
    "        id SERIAL PRIMARY KEY, \n",
    "        hnuser TEXT, \n",
    "        date TIMESTAMP, \n",
    "        comment TEXT,\n",
    "        embedding vector(1536)\n",
    "        );\"\"\"\n",
    "    )\n",
    "\n",
    "conn.commit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "post = posts[0]\n",
    "\n",
    "msg = firstPrompt.format(job_posting = post['comment'])\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "response = model.invoke(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the JSON string to a Python dictionary\n",
    "initial_parsed_datum = json.loads(response.content)\n",
    "parsed_data = [ initial_parsed_datum ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  json\n",
    "\n",
    "result = {}\n",
    "keys = []\n",
    "\n",
    "examplesStr = \"\"\n",
    "postItems = posts[:2]\n",
    "\n",
    "for i in range(len(postItems)):\n",
    "    if i != 0:\n",
    "        msg = subsequentPrompt.format(job_posting = postItems[i]['comment'], json_examples = examplesStr, key_values = \", \".join(keys))\n",
    "        \n",
    "        print(msg)\n",
    "        resp = model.invoke(msg)\n",
    "        parsed_datum = json.loads(resp.content)\n",
    "        \n",
    "        for  job in  parsed_datum:\n",
    "            parsed_data.append(job)\n",
    "\n",
    "        print(parsed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  json\n",
    "\n",
    "result = {}\n",
    "keys = []\n",
    "\n",
    "examplesStr = \"\"\n",
    "postItems = posts[:2]\n",
    "\n",
    "for i in range(len(postItems)):\n",
    "    if i != 0:\n",
    "        msg = subsequentPrompt.format(job_posting = postItems[i]['comment'], json_examples = examplesStr, key_values = \", \".join(keys))\n",
    "\n",
    "        print(msg)\n",
    "        resp = model.invoke(msg)\n",
    "        parsed_datum = json.loads(resp.content)\n",
    "        for  job in  parsed_datum:\n",
    "            parsed_data.append(job)\n",
    "\n",
    "        # We don't care much for the shape of the json object the machine generates, as long as it remains uniform. So, we use the first 5 outputs as examples for the rest.\n",
    "        if i < 5:\n",
    "            itemStr = map(lambda x: json.dumps(x), parsed_data)\n",
    "            examplesStr += \" \".join(itemStr)\n",
    "\n",
    "        if i == 4 or i == 0:\n",
    "            print('\\n\\n', msg)\n",
    "            print ('\\n\\n', examplesStr)\n",
    "        # We don't care much for the shape of the json object the machine generates, as long as it remains uniform. So, we use the first 5 outputs as examples for the rest.\n",
    "        if i < 5:\n",
    "            itemStr = map(lambda x: json.dumps(x), parsed_data)\n",
    "            examplesStr += \" \".join(itemStr)\n",
    "\n",
    "        if i == 4 or i == 0:\n",
    "            print('\\n\\n', msg)\n",
    "            print ('\\n\\n', examplesStr)\n",
    "\n",
    "        print(parsed_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the iteration over the request so we don't do it unnecessarily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(parsed_data)):\n",
    "        # keys needs to be a unique list of keys\n",
    "        # so we can't just add the keys of the new datum\n",
    "        # we need to add only the keys that are not already in keys\n",
    "\n",
    "        jobdesc = parsed_data[i]\n",
    "        for job in jobdesc:\n",
    "            print(job)\n",
    "            # parsed_data_keys = list(job.keys()) \n",
    "            # for key in parsed_data_keys:\n",
    "            #     if key not in keys:\n",
    "            #         keys.append(key)\n",
    "            #         # curs.execute(\"ALTER TABLE parsedPosts ADD COLUMN IF NOT EXISTS %s TEXT\", (key,))\n",
    "            #         conn.commit()\n",
    "\n",
    "            # keyStr = \", \".join(keys)\n",
    "\n",
    "            # curs.execute(\"INSERT INTO posts (hnuser, date, comment, %s) VALUES (%s, %s, %s, %s)\", (posts[i]['hnuser'], posts[i]['date'], posts[i]['comment'], parsed_datum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# let's see how frequently each key appears\n",
    "tally = {}\n",
    "keys\n",
    "for key in keys:\n",
    "#     result[key] = [datum[key] for datum in parsed_data]\n",
    "    tally[key] = sum([1 for datum in parsed_data if key in datum])\n",
    "\n",
    "# result, tally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add all the gathered keys to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    cur.execute(f\"ALTER TABLE parsedPosts ADD COLUMN IF NOT EXISTS  \\\"{key}\\\"  TEXT\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a SQL query that posts by our new keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"INSERT INTO parsedPosts (\"+ \", \".join(keys) +\") VALUES (\" + \", \".join([\"%s\" for key in keys]) + \")\"\n",
    "\n",
    "conn, cur = connect()\n",
    "\n",
    "# for i in range(len(parsed_data)):\n",
    "#     datum = parsed_data[i]\n",
    "#     datum_keys = list(datum.keys())\n",
    "\n",
    "#     for key in keys:\n",
    "#         if key not in datum_keys:\n",
    "#             datum[key] = None\n",
    "\n",
    "#     values = [datum[key] for key in keys]\n",
    "#     valuees = [str(value) for value in values]\n",
    "#     print(values)\n",
    "#     # cur.execute(sql_query, valuees)\n",
    "#     # conn.commit()\n",
    "\n",
    "cur.execute(\"SELECT * FROM parsedPosts\")\n",
    "\n",
    "cur.fetchall()\n",
    "\n",
    "# cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<unknown>:3: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
