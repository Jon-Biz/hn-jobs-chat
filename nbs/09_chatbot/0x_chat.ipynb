{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import getpass\n",
    "# import os\n",
    "\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import getpass\n",
    "# import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "helperPrompt  = \"\"\"You are a job search assistant. \n",
    "You are helping a job searcher find jobs to apply for. From the list of jobs you have, you need to help the job searcher find the jobs that are relevant to them. You can ask the job searcher questions to help you understand what they are looking for. \n",
    "\n",
    "The current requirements of that the user has provided will be provided to you with their latest message, along with the search results that the search engine has returned for those requirements. If the search results doesn't return any results let the user know. Do not refer to or discuss any job postings that aren't in the search results. \n",
    "\"\"\"\n",
    "\n",
    "basePrompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            helperPrompt,\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = basePrompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirementsPrompt  = \"\"\"Current search requirements are: {\n",
    "    \"Job Title\": \"Software Engineer\",\n",
    "    \"Location\": \"Remote\",\n",
    "    \"Company\": \"Google\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "searchResultsPrompt = \"\"\"\n",
    "Current search results are: [\n",
    "    {\n",
    "        \"Job Title\": \"Software Engineer\",\n",
    "        \"Location\": \"Remote\",\n",
    "        \"Company\": \"Google\",\n",
    "        \"Status\": \"Pending\"\n",
    "    },\n",
    "    {\n",
    "        \"Job Title\": \"Software Engineer\",\n",
    "        \"Location\": \"Onsite\",\n",
    "        \"Company\": \"Facebook\",\n",
    "        \"Status\": \"Pending\"\n",
    "    },\n",
    "    {\n",
    "        \"Job Title\": \"Software Engineer\",\n",
    "        \"Location\": \"Remote\",\n",
    "        \"Company\": \"Amazon\",\n",
    "        \"Status\": \"Pending\"\n",
    "    }\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory\n",
    ")\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "config = {\"configurable\": {\"session_id\": \"abc4\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_previous_RAG_info(session_id: str) -> dict:\n",
    "    history = get_session_history(session_id)\n",
    "\n",
    "    alteredHistory = []\n",
    "\n",
    "    for message in history.messages:\n",
    "        if type(message) is tuple:\n",
    "            msgType, text = message\n",
    "            if \"Current search requirements are\" not in text:\n",
    "                if \"Current search results are\" not in text:\n",
    "                    alteredHistory.append(message)    \n",
    "        elif type(message) is HumanMessage:\n",
    "            alteredHistory.append(message)\n",
    "        else:\n",
    "            alteredHistory.append(message)\n",
    "\n",
    "    history.messages = alteredHistory\n",
    "\n",
    "    return {\"session_id\": session_id, \"messages\": alteredHistory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "requirementsPrompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"Current search requirements are: {requirements}\"\"\")\n",
    "\n",
    "def getRequirementsPrompt(requirements):\n",
    "    return requirementsPrompt.format(requirements=requirements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "searchPrompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"Search results meeting those requirements are: {requirements}\"\"\")\n",
    "\n",
    "def getSearchResultsPrompt(requirements):\n",
    "    return searchPrompt.format(requirements=requirements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def getChatResponse(input, requirements, searchResults):\n",
    "    # Remove the previous RAG info, so we can re-run the bot with new RAG info\n",
    "    remove_previous_RAG_info(\"abc4\")\n",
    "\n",
    "    requirementsPrompt = getRequirementsPrompt(requirements)\n",
    "    searchResultsPrompt = getSearchResultsPrompt(searchResults)\n",
    "\n",
    "    response = with_message_history.invoke(\n",
    "        { \"messages\": [\n",
    "            (   \"system\",\n",
    "                requirementsPrompt\n",
    "            ),\n",
    "            (   \"system\",\n",
    "                searchResultsPrompt\n",
    "            ),\n",
    "            HumanMessage(content=input)]\n",
    "        },\n",
    "        config=config,\n",
    "    )\n",
    "    \n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
